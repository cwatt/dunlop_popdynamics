{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np\n",
    "\n",
    "# Provide the directory for your index and read files (you can do multiple independently in one go)\n",
    "growthrate = '/home/cassi/dunlop_popdynamics'\n",
    "# CW: this is the directory where I want to put my outputs from the pipeline\n",
    "\n",
    "# Prepare an object with the name of the library, the name of the directory object (created above), and the metadatafile name\n",
    "#datasets = [['name',directory1,'metadata1','domain of life',raw reads directory],['name',directory2,'metadata2','domain of life']]\n",
    "datasets = [['growthrate', growthrate,'bacteria']]\n",
    "\n",
    "# Set # of Processors to Use\n",
    "processors = \"20\"\n",
    "# CW: there are 40 processers total, check with others to see how many are being used, affects speed of pipeline\n",
    "\n",
    "# Classification Database to Use \n",
    "# options: \"Silva\" [default] | \"GreenGenes\" \n",
    "db = \"Silva\"\n",
    "# CW: use Silva for bacteria, need UNITE or ITS1db databases for fungi\n",
    "\n",
    "## Enter Minimum Support for Keeping QIIME Classification\n",
    "# Note: Classifications that do not meet this criteria will simply be retained, but labeled 'putative'\n",
    "min_support = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Classify Seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example of creating Silva Classifier DB  (very slow: use a pre-built one if possible)\n",
    "\n",
    "#### For Silva, remove all the alignment information (unsure of the impact of keeping it) using the following python code:\n",
    "```python \n",
    "import re\n",
    "from Bio import SeqIO\n",
    "\n",
    "output = open(\"silva.nr_v128.fasta\", \"w\")\n",
    "\n",
    "for record in SeqIO.parse(open(\"silva.nr_v128.align\", \"rU\"), \"fasta\") :\n",
    "    seq = str(record.seq)\n",
    "    seq = re.sub(\"\\.|-\",\"\",seq)  # Remove \".\" and \"-\"\n",
    "\n",
    "    output.write(\">\"+record.id+\"\\n\"+seq+\"\\n\")```\n",
    "\n",
    "#### Import fasta sequence file and taxonomy file as .qza\n",
    "```bash\n",
    "qiime tools import\n",
    "  --type 'FeatureData[Sequence]'\n",
    "  --input-path silva.nr_v128.fasta\n",
    "  --output-path silva.nr_v128.qza\n",
    "\n",
    "qiime tools import \n",
    "  --type 'FeatureData[Taxonomy]' \n",
    "  --source-format HeaderlessTSVTaxonomyFormat \n",
    "  --input-path silva.nr_v128.tax \n",
    "  --output-path silva.nr_v128.taxonomy.qza```\n",
    "\n",
    "#### Run QIIME2 'fit-classifier-naive-bayes'\n",
    "```bash\n",
    "qiime feature-classifier fit-classifier-naive-bayes \n",
    "  --i-reference-reads silva.nr_v128.qza \n",
    "  --i-reference-taxonomy silva.nr_v128.taxonomy.qza \n",
    "  --o-classifier silva.nr_v128.nb.classifier.qza```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FeatureData[Taxonomy] to: /home/cassi/dunlop_popdynamics/reclassify_silva138/growthrate.taxonomy.final.qza\n",
      "Saved Visualization to: /home/cassi/dunlop_popdynamics/reclassify_silva138/growthrate.taxonomy.final.summary.qzv\n"
     ]
    }
   ],
   "source": [
    "## Note: Different QIIME2 versions can conflict with previously donwloaded databases. This section might have to be updated.\n",
    "classification_db = \"/home/cassi/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "        \n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    domain = dataset[2]\n",
    "\n",
    "    # Classify\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-classifier classify-sklearn\",\n",
    "        \"--i-classifier\",\n",
    "        classification_db,\n",
    "        \"--i-reads \"+directory+\"/output/\"+name+\".rep.seqs.final.qza\",\n",
    "        \"--o-classification \"+directory+\"/reclassify_silva138/\"+name+\".taxonomy.final.qza\",\n",
    "        \"--p-n-jobs\",\n",
    "        processors\n",
    "    ]))\n",
    "\n",
    "    # Output Summary\n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+directory+\"/reclassify_silva138/\"+name+\".taxonomy.final.qza\",\n",
    "        \"--o-visualization \"+directory+\"/reclassify_silva138/\"+name+\".taxonomy.final.summary.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Function to Re-Format Taxonomy File to Contain Full Column Information \n",
    "# and factor in the certain of the taxonomic assignment\n",
    "\n",
    "def format_taxonomy(tax_file, classification_db, min_support):\n",
    "    output = open(re.sub(\".tsv\",\".fixed.tsv\",tax_file), \"w\")\n",
    "\n",
    " \n",
    "    # Silva db lacks species classifications\n",
    "    if classification_db == \"GreenGenes\":\n",
    "        full_rank_length = 7\n",
    "        output.write(\"\\t\".join([\"OTU\",\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"])+\"\\n\")\n",
    "    else:\n",
    "        full_rank_length = 6  \n",
    "        output.write(\"\\t\".join([\"OTU\",\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\"])+\"\\n\")\n",
    "        \n",
    "    with open(tax_file, \"r\") as f:\n",
    "        next(f) #skip header\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.split(\"\\t\")\n",
    "\n",
    "            read_id = line[0]\n",
    "            tax_string = line[1]\n",
    "\n",
    "            ## Remove All Underscore Garbage (I need aesthetics)\n",
    "            if classification_db == \"GreenGenes\":\n",
    "                tax_string = re.sub(\"k__|p__|c__|o__|f__|g__|s__\",\"\",tax_string)\n",
    "            else:\n",
    "                tax_string = re.sub(\"_cl|_or|_fa|_ge\",\"\",tax_string)\n",
    "            \n",
    "            # Split full rank into ranks\n",
    "            full_rank = tax_string.split(\";\")\n",
    "          \n",
    "            # Getting trailing empty tab in Silva\n",
    "            if full_rank[len(full_rank)-1] == \"\":\n",
    "                    full_rank = full_rank[:-1]\n",
    "                    \n",
    "            ## Identify the Lowest Classified Taxonomic Rank\n",
    "            # Account for cases when a taxonomic rank contains an empty space (common in GreenGenes output)\n",
    "            last_classified = full_rank[len(full_rank)-1]            \n",
    "\n",
    "            count = 1\n",
    "            while last_classified == \" \":\n",
    "                last_classified = full_rank[len(full_rank)-count]\n",
    "                count = count + 1\n",
    "\n",
    "            # Annotate the last classified as 'putative' if it does not meet the minimum support criteria\n",
    "            # Older versions of this script contain code to designate all taxonomic ranks as 'putative' in this case, but \n",
    "            # this seems conservative\n",
    "            if float(line[2]) < float(min_support):\n",
    "                    full_rank[full_rank.index(last_classified)] = \"putative \"+last_classified\n",
    "                    last_classified = \"putative \"+last_classified\n",
    "                    \n",
    "            # Add in columns containing unclassified taxonomic information\n",
    "            try: # In Silva, many classifications are a single entry (which breaks from the reliance on lists for full_rank.index)\n",
    "                for n in range(full_rank.index(last_classified)+1, full_rank_length, 1):               \n",
    "                    try:\n",
    "                        full_rank[n] = \"unclassified \"+last_classified\n",
    "                    except:\n",
    "                        full_rank.append(\"unclassified \"+last_classified)\n",
    "            except:\n",
    "                for n in range(0, full_rank_length, 1):               \n",
    "                    try:\n",
    "                        full_rank[n] = \"unclassified \"+last_classified\n",
    "                    except:\n",
    "                        full_rank.append(\"unclassified \"+last_classified)\n",
    "                    \n",
    "            # Clean-up the trailing whitespace introduced in Silva classification \n",
    "            if classification_db == \"Silva\":\n",
    "                full_rank = [x.strip(' ') for x in full_rank]\n",
    "\n",
    "            # Write Taxonomy to File\n",
    "            output.write(read_id+\"\\t\"+'\\t'.join(full_rank)+\"\\n\")\n",
    "            \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported /home/cassi/dunlop_popdynamics/reclassify_silva138/growthrate.taxonomy.final.qza as TSVTaxonomyDirectoryFormat to directory /home/cassi/dunlop_popdynamics/reclassify_silva138/\n",
      "mv: missing destination file operand after '/output/taxonomy.fixed.tsv'\n",
      "Try 'mv --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## Export from QIIME2\n",
    "\n",
    "# CW: had to remove first / in front of every output\n",
    "\n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    domain = dataset[2]\n",
    "\n",
    "    # Export Classifications\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+directory+\"/reclassify_silva138/\"+name+\".taxonomy.final.qza\",\n",
    "        \"--output-path \"+directory+\"/reclassify_silva138/\"\n",
    "    ]))\n",
    "    \n",
    "    # Reformat Classifications to meet phyloseq format   \n",
    "    format_taxonomy(directory+\"/reclassify_silva138/taxonomy.tsv\", db, min_support)\n",
    "\n",
    "    # Rename Exported Files\n",
    "    %mv $directory/output/taxonomy.fixed.tsv $tax_file"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
