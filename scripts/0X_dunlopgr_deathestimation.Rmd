---
title: "Untitled"
author: "Cassandra Wattenburger"
date: "12/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_chunk$set(message = FALSE)
```

```{r}
rm(list=ls())

library("tidyverse")
library("lmtest")

sessionInfo()
```

Applying success from recent SFA2 experiment here to see if I can estimate death in this dataset.

# Import data

Normalized abundances, estimated growth.

```{r}
# Normalized abundance data
norm <- readRDS("../rdata.files/gr_ucosm.norm.clean.rds")

# Growth estimates
growth_est <- readRDS("../rdata.files/gr_gr.paprica.clean.rds")

# Metadata
meta <- read.table(file="../metadata/growthrate_metadata.tsv", sep = '\t', header=TRUE)
```

# Prepare normalized abundance data for death estimation

Same steps as 03_dunlopgr_grestimation.Rmd, with additional steps:
* Only include ASVs with estimated growth
* Only look for death in time points after growth period ended

```{r}
# Create unique labels for each time series
norm_label <- mutate(norm, Label = paste0(Soil, Amendment, Replicate, ASV))
growth_label <- mutate(growth_est, Label = paste0(Soil, Amendment, Replicate, ASV))

# Remove 0s
norm_zerorm <- filter(norm_label, norm_abund > 0)

# Remove time series with < 3 tps remaining
occurences <- norm_zerorm %>% 
  group_by(Soil, Amendment, Replicate, ASV) %>% 
  summarize(occurs = n()) %>% 
  filter(occurs > 2) %>% 
  ungroup()

norm_3tp <- inner_join(norm_zerorm, occurences) %>% 
  select(everything(), -occurs)

# Natural log transform
norm_ln <- mutate(norm_3tp, abund_ln = log(norm_abund))

# Remove ASVs without a growth estimate
asvs_grew <- as.character(unique(growth_label$Label))
norm_grew <- filter(norm_ln, Label %in% asvs_grew)

# Isolate time points after end of growth for each time series
norm_after <- data.frame()
for (label in as.character(unique(growth_label$Label))) {
  end_day <- growth_label[growth_label$Label==label,]$end_day
  norm_subset <- filter(norm_ln, Label==label & Day >= end_day)
  # Make sure there are enough time points left to try to fit model
  if (nrow(norm_subset) < 3) {
    next
  }
  else {
    norm_after <- bind_rows(norm_subset, norm_after)
  }
}

norm_prepped <- norm_after
```

# Window estimates: Fit linear model to time series

Same method as 03_dunlopgr_grestimation.Rmd but looking for slope < 0 instead.

```{r}
# Save estimate function
savefit <- function(start, end, datasub, output) { # Start point, end point, time series data, output dataframe
  est <- NULL; coeff <- NULL; resids <- NULL; pval <- NULL; thisrow <- data.frame() # clear previous
  est <- lm(abund_ln ~ Day, data=datasub[start:end,])
  coeff <- est$coefficients[2]
  resids <- sum(abs(resid(est)))
  pval <- summary(est)$coefficients[2,4]
  thisrow <- bind_cols(Label=label, start=start, end=end, coeff=coeff, pval=pval, residuals=resids, row.names <- NULL)
  output <- bind_rows(output, thisrow)
  return(output)
}

# Fit linear model with sliding window
death_est <- data.frame()
for (label in as.character(unique(norm_prepped$Label))) {
  # Subset one time series
  datasub <- data.frame()
  datasub <- norm_prepped[norm_prepped$Label==label,] %>%  # subset growth curve
    arrange(Day)
  stop <- FALSE
  # Save time series info
  label <- NULL
  label <- as.character(unique(datasub$Label))
  
  # Sliding window
  for (b in 1:(nrow(datasub)-2)) { # start of window
    #if (stop == TRUE) {break} this would stop the loop after the first solution is found, but we decided to consider all windows instead
    start <- b
    stop <- FALSE # this ensures all windows are considered (for each new b/window, stop is reset to false)
    for (e in (b+2):nrow(datasub)) { # end of window
      if (stop == TRUE) {break} # stop extending the window if a solution is found
   
      # Fit linear model to window
      test_lm <- NULL; test_pval <- NULL; test_coeff <- NULL
      test_lm <- lm(abund_ln ~ Day, data=datasub[b:e,])
      test_pval <- summary(test_lm)$coefficients[2,4]
      test_coeff <- test_lm$coefficients[2]

      # Extend the window
      if (test_pval <= 0.05 & test_coeff < 0 & e < nrow(datasub)) { # good fit, but more data might improve?
        for (x in ((e+1):nrow(datasub))) { # extend this window to see if it improves
          if (stop == TRUE) {break} # stop extending if the solution improves or if hit end of time series
          testprev_lm <- NULL; testprev_pval <- NULL; testprev_coeff <- NULL; testnew_lm <- NULL; testnew_pval <- NULL; testnew_coeff <- NULL
          testprev_lm <- lm(abund_ln ~ Day, data=datasub[b:(x-1),])
          testprev_pval <- summary(testprev_lm)$coefficients[2,4]
          testprev_coeff <- testprev_lm$coefficients[2]
          testnew_lm <- lm(abund_ln ~ Day, data=datasub[b:x,])
          testnew_pval <- summary(testnew_lm)$coefficients[2,4]
          testnew_coeff <- testnew_lm$coefficients[2]
          
          # Continue extending the window
          if (testnew_pval <= testprev_pval & testnew_coeff < 0 & x < nrow(datasub)) { # if adding data improved (or didn't hurt) the estimate, keep extending
            next
          }
          
          # No improvement
          else if (testnew_pval > testprev_pval & testprev_coeff < 0 & x < nrow(datasub)) { # if adding data did not improve the estimate, stop
            end <- x-1
            death_est <- savefit(start, end, datasub, death_est) # where it tried to save but failed, think issue is in savefit function
            stop <- TRUE
          }
          
          # No more data pts to fit
          else if (testnew_pval <= testprev_pval & testnew_coeff < 0 & x == nrow(datasub)) { # improved but no more data
            end <- x
            death_est <- savefit(start, end, datasub, death_est)
            stop <- TRUE
          } 
        }
      }
      
      # No more data pts to fit
      else if (test_pval <= 0.05 & test_coeff < 0 & e==nrow(datasub)) { # meets threshold but no remaining points to extend
        end <- e
        death_est <- savefit(start, end, datasub, death_est)
        stop <- TRUE
      }
    }
  }
}
```

### Remove "essentially perfect fits"

I can't find any guidance on how to determine whether or not a fit is "perfect" but I know that the residuals are essentially equally to 0 for perfect fits. I'll use 0.0001 as a filtering threshold for removal.

```{r}
# Remove "perfect" fits as precaution
death_noperf <- filter(death_est, residuals >= 0.0001)
nrow(death_est)
nrow(death_noperf)
```

None were removed.

### Select best fit for each time series

* Smallest slope p-value

```{r}
# Best p-value for each curve
death_lowestp <- death_noperf %>% 
  group_by(Label) %>% 
  summarize(pval = min(pval)) %>% 
  ungroup()

death_best <- semi_join(death_noperf, death_lowestp)

nrow(death_best)
```

### False positive control

Histogram of quality filtered p-values from actual estimates:

```{r}
hist(death_best$pval, xlab="P-values", main="Histogram of quality filtered p-values")
```

That doesn't look promising.

See: http://varianceexplained.org/statistics/interpreting-pvalue-histogram/

I'm choosing to use a permutation approach where I use my growth estimating algorhithm on randomly generated data with characteristics of the real data. I'll use this false positive information to filter my real estimates. Traditional false positive control methods are far too conservative for my dataset.

### Simulate random data

Completely random data designed to reflect actual data, if we detect "significant" growth rate estimates from this, we must control for that, because the same thing can happen in our actual data.

Information about real dataset to use for simulating random data:
* number of time points
* min and max of abundance

```{r, results="show"}
# Minimum and maximum relational abund_ln
min_abund_ln <- min(norm_prepped$abund_ln)
max_abund_ln <- max(norm_prepped$abund_ln)
avg_abund_ln <- mean(norm_prepped$abund_ln)
sd_abund_ln <- sd(norm_prepped$abund_ln)

hist(norm_prepped$abund_ln)

# Number of time points
num_tps <- norm_prepped %>% 
  group_by(Label) %>% 
  summarize(num_points = n()) %>% 
  ungroup()

min_pts <- min(num_tps$num_points)
max_pts <- max(num_tps$num_points)
avg_pts <- mean(num_tps$num_points)
sd_pts <- sd(num_tps$num_points)

hist(num_tps$num_points)
```

Simulate random time series:

```{r}
set.seed(2021)

# Set time points, remove anything below day 0.667 (minimum window of growth)
tps <- unique(norm$Day)
tps <- na.omit(tps)
tps <- tps[! tps %in% c(0.000, 0.333, 0.667)]

# Generate using normal distributions
sim_data <- data.frame()
cont <-  TRUE
counter <- 1
while (cont == TRUE) {
  # Stop loop once 1000 simulations have been created
  if (counter == 1001) {
    cont <-  FALSE
  } 
  else {
    thisrow <- data.frame(); hold <- NULL; rand_abund_ln = NULL; rand_pts = NULL; rand_days = NULL # reset values
    # Generate number of time points
    rand_pts <- ceiling(rnorm(1, mean=avg_pts, sd=sd_pts))
    # Make sure number of tps doesn't fall outside min/max
    if (rand_pts <= min_pts | rand_pts >= max_pts) {
      next
      }
    else {
      # Generate abundance for each point
      rand_abund_ln <- rnorm(rand_pts, mean=avg_abund_ln, sd=sd_abund_ln) 
      # Make sure abundances don't fall outside min/max
      if (min(rand_abund_ln) <= min_abund_ln | max(rand_abund_ln) >= max_abund_ln) {
        next
      }
      else {
        # Assign a day to each point
        rand_day <- sort(sample(tps, size=rand_pts, replace=FALSE))
        hold <- cbind(rep(counter, rand_pts), rand_day, rand_abund_ln)
        sim_data= rbind(sim_data, hold)
        counter <- counter + 1
      }
    }
  }
}
colnames(sim_data)[1] <- "simulation"

# Compare simulation to actual data
# Abundances
hist(sim_data$rand_abund_ln)

# Number of data points
sim_num_points <- sim_data %>% 
  group_by(simulation) %>% 
  summarize(num_pts = n()) %>% 
  ungroup() %>% 
  mutate(num_pts = as.numeric(num_pts))
hist(sim_num_points$num_pts)
```

Looks pretty comparable to actual data properties.

Save simulated data:

* for reproducibility

```{r, eval=FALSE}
saveRDS(sim_data, file="../rdata.files/gr_deathsimulation.rds")
```

View some simulated time series:

```{r}
# Choose randomly
sim_data %>%
  filter(simulation == sample(1:1000, 1)) %>% 
  ggplot(aes(x=rand_day, y=rand_abund_ln)) +
    geom_point() +
    geom_line() +
    theme_test()

sim_data %>%
  filter(simulation == sample(1:1000, 1)) %>% 
  ggplot(aes(x=rand_day, y=rand_abund_ln)) +
    geom_point() +
    geom_line() +
    theme_test()

sim_data %>%
  filter(simulation == sample(1:1000, 1)) %>% 
  ggplot(aes(x=rand_day, y=rand_abund_ln)) +
    geom_point() +
    geom_line() +
    theme_test()

sim_data %>%
  filter(simulation == sample(1:1000, 1)) %>% 
  ggplot(aes(x=rand_day, y=rand_abund_ln)) +
    geom_point() +
    geom_line() +
    theme_test()
```

Estimate "death" on simulated data:

```{r}
# Save estimate function
savefit <- function(start, end, datasub, output) { # Start point, end point, time series data, output dataframe
  est <- NULL; coeff <- NULL; resids <- NULL; pval <- NULL; thisrow <- data.frame() # clear previous
  est <- lm(rand_abund_ln ~ rand_day, data=datasub[start:end,])
  coeff <- est$coefficients[2]
  resids <- sum(abs(resid(est)))
  pval <- summary(est)$coefficients[2,4]
  thisrow <- bind_cols(simulation=s, start=start, end=end, coeff=coeff, pval=pval, residuals=resids, row.names <- NULL)
  output <- bind_rows(output, thisrow)
  return(output)
}

# Fit linear model with sliding window
sim_est <- data.frame()
for (s in as.character(unique(sim_data$simulation))) {
  # Subset one time series
  datasub <- data.frame()
  datasub <- sim_data[sim_data$simulation==s,] %>%  # subset growth curve
    arrange(rand_day)
  stop <- FALSE
  # Save time series info
  simulation <- NULL
  simulation <- s
  
  # Sliding window
  for (b in 1:(nrow(datasub)-2)) { # start of window
    #if (stop == TRUE) {break} this would stop the loop after the first solution is found, but we decided to consider all windows instead
    start <- b
    stop <- FALSE # this ensures all windows are considered (for each new b/window, stop is reset to false)
    for (e in (b+2):nrow(datasub)) { # end of window
      if (stop == TRUE) {break} # stop extending the window if a solution is found
   
      # Fit linear model to window
      test_lm <- NULL; test_pval <- NULL; test_coeff <- NULL
      test_lm <- lm(rand_abund_ln ~ rand_day, data=datasub[b:e,])
      test_pval <- summary(test_lm)$coefficients[2,4]
      test_coeff <- test_lm$coefficients[2]

      # Extend the window
      if (test_pval <= 0.05 & test_coeff < 0 & e < nrow(datasub)) { # good fit, but more data might improve?
        for (x in ((e+1):nrow(datasub))) { # extend this window to see if it improves
          if (stop == TRUE) {break} # stop extending if the solution improves or if hit end of time series
          testprev_lm <- NULL; testprev_pval <- NULL; testprev_coeff <- NULL; testnew_lm <- NULL; testnew_pval <- NULL; testnew_coeff <- NULL
          testprev_lm <- lm(rand_abund_ln ~ rand_day, data=datasub[b:(x-1),])
          testprev_pval <- summary(testprev_lm)$coefficients[2,4]
          testprev_coeff <- testprev_lm$coefficients[2]
          testnew_lm <- lm(rand_abund_ln ~ rand_day, data=datasub[b:x,])
          testnew_pval <- summary(testnew_lm)$coefficients[2,4]
          testnew_coeff <- testnew_lm$coefficients[2]
          
          # Continue extending the window
          if (testnew_pval <= testprev_pval & testnew_coeff < 0 & x < nrow(datasub)) { # if adding data improved (or didn't hurt) the estimate, keep extending
            next
          }
          
          # No improvement
          else if (testnew_pval > testprev_pval & testprev_coeff < 0 & x < nrow(datasub)) { # if adding data did not improve the estimate, stop
            end <- x-1
            death_est <- savefit(start, end, datasub, death_est) # where it tried to save but failed, think issue is in savefit function
            stop <- TRUE
          }
          
          # No more data pts to fit
          else if (testnew_pval <= testprev_pval & testnew_coeff < 0 & x == nrow(datasub)) { # improved but no more data
            end <- x
            death_est <- savefit(start, end, datasub, death_est)
            stop <- TRUE
          } 
        }
      }
      
      # No more data pts to fit
      else if (test_pval <= 0.05 & test_coeff < 0 & e==nrow(datasub)) { # meets threshold but no remaining points to extend
        end <- e
        sim_est <- savefit(start, end, datasub, sim_est)
        stop <- TRUE
      }
    }
  }
}
```

Remove "essentially perfect fits":

```{r}
# Remove "perfect" fits as precaution
sim_noperf <- filter(sim_est, residuals >= 0.0001)
nrow(sim_est)
nrow(sim_noperf)
```

None were removed.

Select best fit for each time series:

* Smallest slope p-value

```{r}
# Best p-value for each curve
sim_lowestp <- sim_noperf %>% 
  group_by(simulation) %>% 
  summarize(pval = min(pval)) %>% 
  ungroup()

sim_best <- semi_join(sim_noperf, sim_lowestp)

nrow(sim_best)
```

False positive rates:

```{r}
# False positives
a <- nrow(sim_best[sim_best$pval <= 0.05,])
b <- nrow(sim_best[sim_best$pval <= 0.025,])
c <- nrow(sim_best[sim_best$pval <= 0.01,])
d <- nrow(sim_best[sim_best$pval <= 0.005,])
e <- nrow(sim_best[sim_best$pval <= 0.001,])
f <- nrow(sim_best[sim_best$pval <= 0.0005,])

false_pos <- data.frame(c(0.05, 0.025, 0.01, 0.005, 0.001, 0.0005), c(a,b,c,d,e,f))
colnames(false_pos)=c("pvalue","false")

ggplot(false_pos, aes(x=pvalue, y=false)) +
  geom_point() +
  geom_smooth(method="lm", linetype=2) +
  labs(title="Relationship between p-value and number of false positives", x="P-value", y="False positives") +
  theme_test()
```

Find 5% false positive allowance p-value threshold

* Using linear model to predict

```{r}
falsepos_lm <- lm(false ~ pvalue, data=false_pos)
falsepos_lm

slope <- summary(falsepos_lm)$coefficients[2,1]
intercept <- summary(falsepos_lm)$coefficients[1,1]
```

To reflect growth estimates, filtering at 5% false positive rate:

```{r}
## 5% false positive allowance
false5_pval <- (50 - intercept)/slope

# ~5% false positives
death_falsepos5 <- subset(death_best, pval <= false5_pval)
nrow(death_falsepos5)
```

# Long estimates: Fit linear model to time series

Fitting to all data points after growth ends. Trying to accomodate high variability and oscillation.

```{r}
# Estimate death over entire remaining time period
death_est_long <- data.frame()
for (label in as.character(unique(norm_prepped$Label))) {
  data_sub <- filter(norm_prepped, Label==label) %>% 
    arrange(Day)
  fit_lm <- NULL; pval <- NULL; est <- NULL # clear prev
  fit_lm <- lm(abund_ln ~ Day, data=data_sub)
  pval <- summary(fit_lm)$coefficients[2,4]
  est <- summary(fit_lm)$coefficients[2,1]
  if (est < 0 & pval < 0.05) {
    this_row <- data.frame(Label=label, slope=est, pval, residuals=sum(abs(resid(fit_lm))))
    death_est_long <- bind_rows(death_est_long, this_row)
  }
  else {next}
}
```

Remove essentially perfect fits:

```{r}
# Remove "perfect" fits as precaution
death_noperf_long <- filter(death_est_long, residuals >= 0.0001)
nrow(death_est_long)
nrow(death_noperf_long)
```

### Control for false positives

```{r}
sim_est_long <- data.frame()
for (sim in as.character(unique(sim_data$simulation))) {
  data_sub <- filter(sim_data, simulation==sim) %>% 
    arrange(rand_day)
  fit_lm <- NULL; pval <- NULL; est <- NULL # clear prev
  fit_lm <- lm(rand_abund_ln ~ rand_day, data=data_sub)
  pval <- summary(fit_lm)$coefficients[2,4]
  est <- summary(fit_lm)$coefficients[2,1]
  if (est < 0 & pval < 0.05) {
    this_row <- data.frame(Simulation=sim, slope=est, pval, residuals=sum(abs(resid(fit_lm))))
    sim_est_long <- bind_rows(sim_est_long, this_row)
  } 
  else {next}
}

dim(sim_est_long)
```

Remove essentially perfect fits:

```{r}
# Remove "perfect" fits as precaution
sim_noperf_long <- filter(sim_est_long, residuals >= 0.0001)
nrow(sim_est_long)
nrow(sim_noperf_long)
```

False positive rates:

```{r}
# False positives
a <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.05,])
b <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.025,])
c <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.01,])
d <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.005,])
e <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.001,])
f <- nrow(sim_noperf_long[sim_noperf_long$pval <= 0.0005,])

false_pos_long <- data.frame(c(0.05, 0.025, 0.01, 0.005, 0.001, 0.0005), c(a,b,c,d,e,f))
colnames(false_pos_long)=c("pvalue","false")

ggplot(false_pos_long, aes(x=pvalue, y=false)) +
  geom_point() +
  geom_smooth(method="lm", linetype=2) +
  labs(title="Relationship between p-value and number of false positives", x="P-value", y="False positives") +
  theme_test()
```

Find 5% false positive allowance p-value threshold:

* Using linear model to predict

```{r}
falsepos_long_lm <- lm(false ~ pvalue, data=false_pos_long)
falsepos_long_lm

slope_long <- summary(falsepos_long_lm)$coefficients[2,1]
intercept_long <- summary(falsepos_long_lm)$coefficients[1,1]
```

To reflect growth estimates, filtering at 5% false positive rate:

```{r}
## 5% false positive allowance
false5_pval_long <- (50 - intercept_long)/slope_long

# ~5% false positives
death_falsepos5_long <- subset(death_noperf_long, pval <= false5_pval_long)
nrow(death_falsepos5_long)
```

None removed.

# Compare estimated slopes between methods

We've decided that if the slope estimates between methods is indistinguishable, we will go with the long fit. If they are different, we will go with the window-fit to reflect possible oscillatory patterns of growth and death.

Isolate time series wtih fits to both long and window model fits:

```{r}
death_long <- death_falsepos5_long
death_window <- death_falsepos5

# Overlaping time series between fitted models
death_overlap <- inner_join(death_long, death_window, by="Label") %>% 
  mutate(same = if_else(residuals.x==residuals.y & pval.x==pval.y, "yes", "no")) %>% 
  filter(same == "no") %>% 
  select(Label, start, end)

# Get slope estimates for each overlapping time series
overlap_labels <- death_overlap$Label
death_long_overlap <- filter(death_long, Label %in% overlap_labels) %>% 
  mutate(fit = "long") %>% 
  select(Label, long_slope=slope)
death_window_overlap <- filter(death_long, Label %in% overlap_labels) %>% 
  mutate(fit = "window") %>%
  select(Label, window_slope=slope) %>% 
  inner_join(death_long_overlap)
```

These overlapping estimates fit the same data window, no point in comparisons.

# Calculate death parameters

### Death rate

Need to look into a specific growth rate equivalent to death? For now, stick to the slope of the linear model.

### Start and end day, change in relational abundance

```{r}
test <- bind_rows(head(death_window), tail(death_window))

# Convert start and end to actual day
death_metrics <- data.frame()
for (l in as.character(unique(death_window$Label))) {
  # Isolate
  norm_label <- norm_prepped %>%
    filter(Label==l) %>% 
    arrange(Day)
  death_label <- filter(death_window, Label==l)
  # Set start and end based on model fit
  if (is.na(death_label$start)) {
    start_pt <- as.numeric(1)
    end_pt <- as.numeric(nrow(norm_label))
  } 
  else {
    start_pt <- death_label$start
    end_pt <- death_label$end
  }
  # Start and end days, length
  start_day <- norm_label[start_pt,]$Day
  end_day <- norm_label[end_pt,]$Day
  length_days <- end_day - start_day
  # Starting and ending abundances, change
  start_abund <- norm_label[start_pt,]$norm_abund
  end_abund <- norm_label[end_pt,]$norm_abund
  change_abund <- end_abund - start_abund
  # Save output
  this_row <- bind_cols(Label = as.character(death_label$Label),
                        start_pt = start_pt, end_pt = end_pt,
                        death_rate = death_label$coeff,
                        start_day = start_day, end_day = end_day, length_days = length_days,
                        start_abund = start_abund, end_abund = end_abund, change_abund = change_abund)
  death_metrics <- bind_rows(death_metrics, this_row)
}
```

# Tidy up and save data

```{r}
# Taxonomic information
tax <- select(norm_prepped, ASV, Domain, Phylum, Class, Order, Family, Genus) %>% 
  unique()

# Metadata
meta <- norm_prepped %>% 
  mutate(Soil = gsub("^([C|S][0-9]+)([Y|N])([1-3])(.+)", "\\1", Label),
         Amendment = gsub("^([C|S][0-9]+)([Y|N])([1-3])(.+)", "\\2", Label),
         Replicate = gsub("^([C|S][0-9]+)([Y|N])([1-3])(.+)", "\\3", Label),
         ASV = gsub("^([C|S][0-9]+)([Y|N])([1-3])(.+)", "\\4", Label)) %>% 
  select(Label, Soil, Amendment, Replicate, ASV) %>% 
  unique()
```

Relational abundances:

```{r}
# Labels of estimated taxa
est_labels <- as.character(death_metrics$Label)

# Extract from relational abundance table and clean up
norm_tidy <- norm_prepped %>% 
  filter(Label %in% est_labels) %>% 
  select(Label, Soil, Amendment, Day, Replicate, ASV:Genus, norm_abund, abund_ln)
```

```{r, eval=FALSE}
saveRDS(norm_tidy, file="../rdata.files/gr_norm_death_estimated.rds")
```

Death estimates:

```{r}
# Add metadata and taxonomic info
death_tidy <- death_metrics %>% 
  left_join(meta, by="Label") %>% 
  left_join(tax) %>% 
  select(Label, Soil, Amendment, Replicate, ASV, start_pt:length_days, start_abund:change_abund, Domain:Genus) %>% 
  mutate(Replicate = as.numeric(Replicate))
```

```{r, eval=FALSE}
saveRDS(death_tidy, file="../rdata.files/gr_death_estimates.rds")
```

# Plot death

```{r}
# For messing with graphs
testing <- head(death_tidy)

# Plot all
for (l in as.character(death_tidy$Label)) {
  # Subset time series
  est_label <- filter(death_tidy, Label==l)
  norm_label <- filter(norm_tidy, Label==l) %>% 
    arrange(Day)
  # Title information
  asv <- est_label$ASV
  tax_info <- filter(tax, ASV == asv)
  title <- paste0(as.character(tax_info$Phylum), ", ", as.character(tax_info$Genus))
  # Graph with estimate
  graph <- ggplot(norm_label, aes(x=Day, y=log(norm_abund))) +
    geom_point(shape=1, size=2, color="#6F7378") +
    geom_line(color="#6F7378") +
    # Death estimate
    geom_smooth(method="lm", data=filter(norm_label, Day >= est_label$start_day & Day <= est_label$end_day),
                linetype=2, color="red") +
    # Formatting
    labs(title=title, x="Day", y="ln ARNIS ratio") +
    theme_test() +
    theme(title = element_text(size=18),
        axis.title = element_text(size=16),
        axis.text = element_text(size=14))
  print(graph)
}

```
